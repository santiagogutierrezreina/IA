{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqaohoArpHPFn2lyaY0vwx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagogutierrezreina/IA/blob/main/Clasificador_de_Imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSuUz6iQT3kr"
      },
      "outputs": [],
      "source": [
        "#Importamos librerias\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenemos el dataset de fashion mnist con las 60.000 imagenes de entrenamiento y 10.000 de test\n",
        "datos, metadatos = tfds.load('fashion_mnist', as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "bRW5eSpdUiEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadatos"
      ],
      "metadata": {
        "id": "iU07WwzKVHAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separamos los datos de entrenamiento y prueba\n",
        "datos_entrenamiento = datos['train']\n",
        "datos_pruebas = datos['test']"
      ],
      "metadata": {
        "id": "F04eliSqVPx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenemos las etiquetas\n",
        "nombres_clases = metadatos.features['label'].names"
      ],
      "metadata": {
        "id": "Ue05sJI3Vc8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nombres_clases"
      ],
      "metadata": {
        "id": "mG5NJK4lVjA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizamos los datos entre 0-1\n",
        "def normalizar(imagenes, etiquetas):\n",
        "  imagenes = tf.cast(imagenes, tf.float32) #Transforma imagenes a un dato tipo float32\n",
        "  imagenes /= 255                          #La divide entre 255 para normalizarla de 0-255 a 0-1\n",
        "  return imagenes, etiquetas\n",
        "\n",
        "#Normalizamos los datos de entrenamiento y test\n",
        "datos_entrenamiento = datos_entrenamiento.map(normalizar) #.map aplica la funcion interna a cada elemento del dataset\n",
        "datos_pruebas = datos_pruebas.map(normalizar)\n",
        "\n",
        "#Agregamos a cache(memoria en lugar de disco)\n",
        "datos_entrenamiento = datos_entrenamiento.cache()\n",
        "datos_pruebas = datos_pruebas.cache()"
      ],
      "metadata": {
        "id": "JWjIdv7vVvRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar una imagen de los datos de prueba\n",
        "for imagen, etiqueta in datos_entrenamiento.take(1): #De momento, solo se imprime la primer imagen\n",
        "  break\n",
        "imagen = imagen.numpy().reshape((28,28)) #Redimensionamos la imagen a 28x28\n",
        "\n",
        "#Dibuja la imagen asi, ay que bonito\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "tUYm_yG0XRFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10)) #Crea una figura de 10\"x 10\"\n",
        "for i , (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)): #Crea un contador con los 25 datos\n",
        "  imagen = imagen.numpy().reshape((28,28))\n",
        "  plt.subplot(5,5,i+1) #Crea una matriz 5x5 donde se almacena cada imagen creada con su etiqueta\n",
        "\n",
        "  #Limpiamos ticks y grilla\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "\n",
        "  #Muestra la imagen en la escala de grises y la etiqueta en el xlabel\n",
        "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "  plt.xlabel(nombres_clases[etiqueta])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iy7up4xyXw1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "    #Creamos la capa entrada (Flatten \"aplasta\" a una sola dimension)\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28,1)), #1 - blanco y negro\n",
        "\n",
        "    #Creamos las capas ocultas densas, con 50 neuronas y la funcion reLU\n",
        "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n",
        "\n",
        "    #softmax se emplea para aplicar la funcion de activacion en la capa de salida, para las redes de clasificacion, asegurando que siempre la salida sea 1\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax) #10 - numero de clases\n",
        "])"
      ],
      "metadata": {
        "id": "w3C6Lfo_ZThM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilamos el modelo\n",
        "modelo.compile(\n",
        "    optimizer='adam', #Optimizador\n",
        "    loss='sparse_categorical_crossentropy', #Funcion de perdida\n",
        "    metrics=['accuracy'] #Metrica\n",
        ")"
      ],
      "metadata": {
        "id": "sNskHTe6ac62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardamos en variables la cantidad de datos de entrenamiento y pruebas\n",
        "num_ej_entrenamiento = metadatos.splits[\"train\"].num_examples\n",
        "num_ej_pruebas = metadatos.splits[\"test\"].num_examples"
      ],
      "metadata": {
        "id": "6GvcfNzbbFqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_ej_entrenamiento)\n",
        "print(num_ej_pruebas)"
      ],
      "metadata": {
        "id": "iuI1in5abL9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos en lotes para no sobrecargar el modelo con la cantidad de datos de prueba\n",
        "TAMANO_LOTE = 32\n",
        "\n",
        "#Separamos los datos en los batches o lotes\n",
        "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE) #Repetimos los datos de entrenamiento de forma aleatoria\n",
        "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
      ],
      "metadata": {
        "id": "Awuz38ufavzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "#Entrenamos el modelo con 5 vueltas, idealmente debe llegar a nna precision del 88%\n",
        "historial = modelo.fit(datos_entrenamiento, epochs=5, steps_per_epoch=math.ceil(num_ej_entrenamiento/TAMANO_LOTE)) #steps-per-epoch va a ser removida, por ende no es relevante"
      ],
      "metadata": {
        "id": "iqGOyMsSbleu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graficamos la funcion de perdida\n",
        "plt.xlabel(\"# Epoca\")\n",
        "plt.ylabel(\"Magnitud de p√©rdida\")\n",
        "plt.plot(historial.history[\"loss\"])"
      ],
      "metadata": {
        "id": "qGR6XU8nck3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pintar una cuadricula con varias predicciones, y marcar si fue correcta (azul) o incorrecta (roja)\n",
        "import numpy as np\n",
        "\n",
        "for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):\n",
        "  imagenes_prueba = imagenes_prueba.numpy()\n",
        "  etiquetas_prueba = etiquetas_prueba.numpy()\n",
        "  predicciones = modelo.predict(imagenes_prueba)\n",
        "\n",
        "def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):\n",
        "  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "  if etiqueta_prediccion == etiqueta_real:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(nombres_clases[etiqueta_prediccion],\n",
        "                                100*np.max(arr_predicciones),\n",
        "                                nombres_clases[etiqueta_real]),\n",
        "                                color=color)\n",
        "\n",
        "def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):\n",
        "  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  grafica = plt.bar(range(10), arr_predicciones, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "\n",
        "  grafica[etiqueta_prediccion].set_color('red')\n",
        "  grafica[etiqueta_real].set_color('blue')\n",
        "\n",
        "filas = 5\n",
        "columnas = 5\n",
        "num_imagenes = filas*columnas\n",
        "plt.figure(figsize=(2*2*columnas, 2*filas))\n",
        "for i in range(num_imagenes):\n",
        "  plt.subplot(filas, 2*columnas, 2*i+1)\n",
        "  graficar_imagen(i, predicciones, etiquetas_prueba, imagenes_prueba)\n",
        "  plt.subplot(filas, 2*columnas, 2*i+2)\n",
        "  graficar_valor_arreglo(i, predicciones, etiquetas_prueba)"
      ],
      "metadata": {
        "id": "LyoDE3Egc95w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tomar cualquier dato para realizar una prediccion\n",
        "imagen = imagenes_prueba[0]\n",
        "imagen = np.array([imagen])\n",
        "prediccion = modelo.predict(imagen)\n",
        "\n",
        "print(\"Prediccion: \" + nombres_clases[np.argmax(prediccion[0])])"
      ],
      "metadata": {
        "id": "oyI18Je5dImN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}